{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead457f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-------------------+------------------+\n",
      "|        Brand|State|Year of Manufacture|   Average Mileage|\n",
      "+-------------+-----+-------------------+------------------+\n",
      "|        Bajaj|Delhi|               2017|             37.42|\n",
      "|        Bajaj|Delhi|               2016|            46.945|\n",
      "|        Bajaj|Delhi|               2018|             70.94|\n",
      "|        Bajaj|Delhi|               2019|             73.38|\n",
      "|         Hero|Delhi|               2018|             99.74|\n",
      "|         Hero|Delhi|               2019|             38.32|\n",
      "|         Hero|Delhi|               2017|             74.84|\n",
      "|         Hero|Delhi|               2016|             76.68|\n",
      "|        Honda|Delhi|               2018| 86.45333333333333|\n",
      "|        Honda|Delhi|               2017|              87.0|\n",
      "|        Honda|Delhi|               2019| 60.26333333333334|\n",
      "|        Honda|Delhi|               2016|             88.64|\n",
      "|          KTM|Delhi|               2019|             63.44|\n",
      "|          KTM|Delhi|               2018|             64.75|\n",
      "|          KTM|Delhi|               2017|             92.63|\n",
      "|     Kawasaki|Delhi|               2017|57.129999999999995|\n",
      "|     Kawasaki|Delhi|               2019| 73.14333333333335|\n",
      "|Royal Enfield|Delhi|               2018| 56.24333333333334|\n",
      "|Royal Enfield|Delhi|               2016| 83.10000000000001|\n",
      "|Royal Enfield|Delhi|               2017|             78.23|\n",
      "+-------------+-----+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Bike Sales Review\").getOrCreate()\n",
    "\n",
    "bike_sales = spark.read.csv(\"bike_sales_india.csv\", header=True, inferSchema=True)\n",
    "result = bike_sales.filter((col(\"Year of Manufacture\") >= 2016) &\\\n",
    "                           (col(\"Year of Manufacture\") <= 2019)& \\\n",
    "                           (col(\"Owner Type\") == \"First\")&\\\n",
    "                           (col(\"City Tier\").isin('Tier 1','Tier 2')))\\\n",
    "                           .groupBy(\"Brand\", \"State\", \"Year of Manufacture\")\\\n",
    ".agg(avg(\"Mileage (km/l)\").alias(\"Average Mileage\")).orderBy(\"State\", \"Brand\").show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
